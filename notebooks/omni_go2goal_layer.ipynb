{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import time\n",
    "\n",
    "from cycler import cycler\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "\n",
    "from dimp.robots import (\n",
    "    OmniInput, OmniRobot, OmniState, RobotMPCData\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Create The Data for the MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 2      # Number of states (x, y)\n",
    "ni = 2      # Number of inputs (vx, vy)\n",
    "\n",
    "nc = 50     # Number of control intervals\n",
    "\n",
    "s0 = cp.Parameter(ns, name=\"s0\")\n",
    "\n",
    "mpc_data = RobotMPCData(\n",
    "    nc=nc,\n",
    "    states_list=[OmniState(s0)] + [OmniState(cp.Variable(ns, name=f\"s{k+1}\")) for k in range(nc)],\n",
    "    statesbar_list=[OmniState(s0)] + [OmniState(cp.Parameter(ns)) for _ in range(nc)],\n",
    "    inputs_list=[OmniInput(cp.Variable(ni, name=f\"i{k}\")) for k in range(nc)],\n",
    "    inputsbar_list=[OmniInput(cp.Parameter(ni)) for _ in range(nc)],\n",
    ")\n",
    "\n",
    "dt = 0.1\n",
    "robot = OmniRobot(dt=dt, mpc_data=mpc_data)\n",
    "\n",
    "# Parameters\n",
    "p_goal = np.array([10.0, 5.0])\n",
    "v_max = 10.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Create The MPC Problem\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "&\\min_{\\substack{s_k, u_k \\\\ \\quad k=1, \\, \\dots, \\, n_c}} \\quad &&\\sum_{k=1}^{n_c} w_1 (p_k - p_\\text{goal})^2 + w_2 u_k^2) \\\\\n",
    "&\\text{s.t.} && x_{k+1} = A_k x_k + B_k u_k, \\\\\n",
    "& && u_k^2 \\leq v_\\text{max}^2.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = cp.Parameter(2, name=\"weights\", nonneg=True)\n",
    "\n",
    "def create_qcqp(nc: int):\n",
    "    objective = cp.Minimize(\n",
    "          0.5 * weights[0] * cp.sum_squares(cp.hstack([mpc_data.statei[i+1] - p_goal for i in range(nc)]))\n",
    "        + 0.5 * weights[1] * cp.sum_squares(cp.hstack([mpc_data.inputi[i] for i in range(nc)]))\n",
    "    )\n",
    "\n",
    "    dynamics_constraints = robot.dt_dynamics_constraint()\n",
    "\n",
    "    input_constraints = [\n",
    "        cp.norm(mpc_data.inputi[i], p=2) - v_max <= 0 for i in range(nc)\n",
    "    ]\n",
    "\n",
    "    constraints = dynamics_constraints + input_constraints\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "\n",
    "    return problem\n",
    "\n",
    "qcqp_problem = create_qcqp(nc=nc)\n",
    "print(type(qcqp_problem))\n",
    "assert qcqp_problem.is_dpp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Simulate the Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8434de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_to(\n",
    "    problem: cp.Problem,\n",
    "    mpc_data: RobotMPCData,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Simulate the robot's motion over the OCP horizon (trajectory optimization).\n",
    "    The OCP is solved once and the entire state-input trajectory is obtained in one go.\n",
    "\n",
    "    Args:\n",
    "        problem (cp.Problem): The optimization problem to solve.\n",
    "        mpc_data (RobotMPCData): The MPC data containing state and input variables.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]: Arrays of states and inputs over the simulation steps of size [steps, ns] and [steps, ni], respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    states = np.zeros((mpc_data.nc+1, ns))\n",
    "    inputs = np.zeros((mpc_data.nc, ni))\n",
    "    \n",
    "    s0 = np.array([0, 0])\n",
    "    mpc_data.statei[0].value = s0\n",
    "\n",
    "    problem.solve()\n",
    "\n",
    "    mpc_data.statei[0].value = mpc_data.statei[1].value\n",
    "\n",
    "    mpc_data.update_bar()\n",
    "    \n",
    "    states[0, :] = s0\n",
    "    for i in range(mpc_data.nc):\n",
    "        states[i+1, :] = mpc_data.statei[i+1].value\n",
    "        inputs[i, :] = mpc_data.inputi[i].value\n",
    "\n",
    "    return states, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_mpc(\n",
    "    problem: cp.Problem,\n",
    "    mpc_data: RobotMPCData,\n",
    "    n_steps: int = 200,\n",
    ") -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Simulate the robot's motion over a fixed number of steps (MPC).\n",
    "    The OCP is solved multiple times and only the first control input is applied at each step.\n",
    "\n",
    "    Args:\n",
    "        problem (cp.Problem): The optimization problem to solve.\n",
    "        mpc_data (RobotMPCData): The MPC data containing state and input variables.\n",
    "        n_steps (int): The number of steps to simulate.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]: Arrays of states and inputs over the simulation steps of size [steps, ns] and [steps, ni], respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    states = np.zeros((n_steps, ns))\n",
    "    inputs = np.zeros((n_steps, ni))\n",
    "\n",
    "    mpc_data.statei[0].value = np.array([0, 0])\n",
    "\n",
    "    for i in range(n_steps):\n",
    "\n",
    "        problem.solve()\n",
    "\n",
    "        mpc_data.statei[0].value = mpc_data.statei[1].value\n",
    "\n",
    "        mpc_data.update_bar()\n",
    "\n",
    "        states[i, :] = mpc_data.statei[1].value\n",
    "        inputs[i, :] = mpc_data.inputi[1].value\n",
    "\n",
    "    return states, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Plot the Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(states: np.ndarray) -> None:\n",
    "    steps = states.shape[0]\n",
    "\n",
    "    xm, xM = states[:, 0].min() - 1, states[:, 0].max() + 1\n",
    "    ym, yM = states[:, 1].min() - 1, states[:, 1].max() + 1\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter(x=states[:, 0], y=states[:, 1],\n",
    "                mode=\"lines\", name=\"Trajectory\",\n",
    "                line=dict(width=2, color=\"rgba(0, 0, 255, 0.5)\", dash='dot')),\n",
    "            go.Scatter(x=[states[0, 0]], y=[states[0, 1]],\n",
    "                mode=\"markers\", name=\"Robot\",\n",
    "                marker=dict(color=\"blue\", size=10)),\n",
    "        ])\n",
    "\n",
    "    fig.update_layout(width=600, height=450,\n",
    "        xaxis=dict(\n",
    "            range=[xm, xM], autorange=False, zeroline=False, scaleanchor=\"y\", title=\"x [m]\"),\n",
    "        yaxis=dict(\n",
    "            range=[ym, yM], autorange=False, zeroline=False, title=\"y [m]\"),\n",
    "        title_text=\"Trajectory\", title_x=0.5,\n",
    "        updatemenus = [dict(type = \"buttons\",\n",
    "            buttons = [\n",
    "                dict(\n",
    "                    args = [None, {\"frame\": {\"duration\": 10, \"redraw\": False},\n",
    "                                    \"fromcurrent\": True, \"transition\": {\"duration\": 10}, \"mode\": \"immediate\"}],\n",
    "                    label = \"Play\",\n",
    "                    method = \"animate\",\n",
    "                )])],\n",
    "    )\n",
    "\n",
    "    fig.update(frames=[\n",
    "        go.Frame(\n",
    "            data=[go.Scatter(x=[states[k, 0]], y=[states[k, 1]])],\n",
    "            traces=[1]\n",
    "        ) for k in range(steps)])\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    fig.write_html(\"omni_robot_mpc.html\", include_plotlyjs=\"cdn\", full_html=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5021a41",
   "metadata": {},
   "source": [
    "### Plot the Trajectory Optimization Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_and_plot_qcqp():\n",
    "    weights.value = np.array([1.0, 1.0])\n",
    "    \n",
    "    states, inputs = simulate_to(qcqp_problem, mpc_data)\n",
    "\n",
    "    plot_trajectory(states)\n",
    "\n",
    "simulate_and_plot_qcqp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8038196",
   "metadata": {},
   "source": [
    "### Create the `CvxpyLayer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvxpylayer = CvxpyLayer(\n",
    "    qcqp_problem,\n",
    "    parameters=[weights, s0],\n",
    "    variables=[mpc_data.statei[i] for i in range(1, nc + 1)] + [mpc_data.inputi[i] for i in range(nc)],\n",
    ")\n",
    "\n",
    "w_th = torch.nn.Parameter(torch.tensor([1.0, 1.0]))\n",
    "s0_th = torch.tensor([0.0, 0.0])\n",
    "\n",
    "optim = torch.optim.Adam([w_th], lr=1e-2)\n",
    "\n",
    "solution = cvxpylayer(w_th, s0_th)\n",
    "\n",
    "solution[0].sum().backward()\n",
    "\n",
    "print(f\"w.grad: {w_th.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_loss(states, inputs):\n",
    "    p_goal_th = torch.tensor(p_goal, requires_grad=True)\n",
    "    \n",
    "    st_cost = torch.stack([(s - p_goal_th).pow(2).sum() for s in states]).sum()\n",
    "    in_cost = torch.stack([u.pow(2).sum()               for u in inputs]).sum()\n",
    "    return 0.5 * 10.0 * st_cost + 0.5 * 1.0 * in_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaaa60bd",
   "metadata": {},
   "source": [
    "### Matplotlib Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cycler = (\n",
    "    cycler(color=['#E41A1C', '#377EB8', '#4DAF4A', '#984EA3', '#FF7F00', '#FFFF33', '#A65628', '#F781BF', '#999999']) +\n",
    "    # cycler(color=['#0072BD', '#D95319', '#EDB120', '#7E2F8E', '#77AC30', '#4DBEEE', '#A2142F']) +\n",
    "    cycler('linestyle', ['-', '--', '-', '--', '-', '--', '-', '--', '-'])\n",
    ")\n",
    "\n",
    "colors = list(default_cycler.by_key()['color'])\n",
    "\n",
    "textsize = 12\n",
    "labelsize = 12\n",
    "\n",
    "plt.rc('font', family='serif', serif='Times')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('xtick', labelsize=textsize)\n",
    "plt.rc('ytick', labelsize=textsize)\n",
    "plt.rc('axes', labelsize=labelsize, prop_cycle=default_cycler)\n",
    "plt.rc('legend', fontsize=textsize)\n",
    "\n",
    "plt.rc(\"axes\", grid=True, xmargin=0)\n",
    "plt.rc(\"grid\", linestyle='dotted', linewidth=0.25)\n",
    "\n",
    "plt.rcParams['figure.constrained_layout.use'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_res(history):\n",
    "    fig, ax = plt.subplots(2, 1)\n",
    "    ax[0].plot([h['loss'] for h in history])\n",
    "    ax[0].set_xlabel(\"Epoch\")\n",
    "    ax[0].set_ylabel(\"Loss\")\n",
    "    ax[0].set_title(\"Loss Evolution\")\n",
    "\n",
    "    ax11 = ax[1].twinx()\n",
    "    ax[1].plot([h['w'][0] for h in history],)\n",
    "    ax[1].set_title(\"Weights Evolution\")\n",
    "    ax[1].set_xlabel(\"Epoch\")\n",
    "    ax[1].set_ylabel(r\"$w_0$\", color=colors[0])\n",
    "    ax[1].tick_params(axis='y', labelcolor=colors[0])\n",
    "\n",
    "    ax11.plot([h['w'][1] for h in history], color=colors[1], linestyle='--')\n",
    "    ax11.set_ylabel(r\"$w_1$\", color=colors[1])\n",
    "    ax11.tick_params(axis='y', labelcolor=colors[1])\n",
    "\n",
    "    fig.set_constrained_layout(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958787ae",
   "metadata": {},
   "source": [
    "### Train 1\n",
    "\n",
    "Compute the loss only over the OCP horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 200\n",
    "history  = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    w_th.copy_(torch.tensor([1.0, 1.0]))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    optim.zero_grad()\n",
    "\n",
    "    s0_th = torch.zeros_like(s0_th)\n",
    "\n",
    "    sol = cvxpylayer(w_th, s0_th)\n",
    "    states = [sol[i] for i in range(nc)]\n",
    "    inputs = [sol[nc + i] for i in range(nc)]\n",
    "\n",
    "    loss = task_loss(states, inputs)\n",
    "    loss.backward()\n",
    "\n",
    "    optim.step()\n",
    "\n",
    "    history.append({\n",
    "        'loss': loss.item(),\n",
    "        'w': copy.deepcopy(w_th.detach().cpu().numpy()),\n",
    "        'dw': copy.deepcopy(w_th.grad.detach().cpu().numpy()),\n",
    "    })\n",
    "    print(f\"Epoch {epoch:2d} | loss = {loss.item():.4f} | w = {w_th.detach().cpu().numpy()}\")\n",
    "\n",
    "plot_training_res(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9722080",
   "metadata": {},
   "source": [
    "### Train 2\n",
    "\n",
    "Compute the loss over a rollout of the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(layer, initial_state, W, n_steps=200):\n",
    "    s_t = initial_state\n",
    "    states, inputs = [], []\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        sol = layer(W, s_t)\n",
    "        \n",
    "        nc = int(len(sol) / 2)\n",
    "        s1 = sol[0]\n",
    "        u0 = sol[nc]\n",
    "\n",
    "        states.append(s1)\n",
    "        inputs.append(u0)\n",
    "\n",
    "        s_t = s1\n",
    "\n",
    "    return states, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bfa8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_short = 1\n",
    "n_steps_rollout = 1\n",
    "\n",
    "qcqp_problem_short_hor = create_qcqp(nc=nc_short)\n",
    "\n",
    "cvxpylayer_short_hor = CvxpyLayer(\n",
    "    qcqp_problem_short_hor,\n",
    "    parameters=[weights, s0],\n",
    "    variables=[mpc_data.statei[i] for i in range(1, nc_short + 1)] + [mpc_data.inputi[i] for i in range(nc_short)],\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    w_th.copy_(torch.tensor([1.0, 1.0]))\n",
    "\n",
    "optim = torch.optim.Adam([w_th], lr=1e-2)\n",
    "\n",
    "n_epochs = 200\n",
    "history  = []\n",
    "for epoch in range(n_epochs):\n",
    "    optim.zero_grad()\n",
    "\n",
    "    s0_th = torch.zeros_like(s0_th)\n",
    "    \n",
    "    states, inputs = rollout(cvxpylayer_short_hor, s0_th, w_th, n_steps=n_steps_rollout)\n",
    "\n",
    "    loss = task_loss(states, inputs)\n",
    "    loss.backward()\n",
    "    \n",
    "    optim.step()\n",
    "\n",
    "    history.append({\n",
    "        'loss': loss.item(),\n",
    "        'w': copy.deepcopy(w_th.detach().cpu().numpy()),\n",
    "        'dw': copy.deepcopy(w_th.grad.detach().cpu().numpy()),\n",
    "    })\n",
    "    print(f\"Epoch {epoch:2d} | loss = {loss.item():.4f} | w = {w_th.detach().cpu().numpy()}\")\n",
    "\n",
    "plot_training_res(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de753e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for nc_short in [1, 2, 5, 10, 20, 50]:\n",
    "    print(f\"nc_short: {nc_short}\")\n",
    "    for n_steps_rollout in [1, 2, 5, 10, 20, 50, 100]:\n",
    "        print(f\"n_steps_rollout: {n_steps_rollout}\")\n",
    "                \n",
    "        mpc_data = RobotMPCData(\n",
    "            nc=nc_short,\n",
    "            states_list=[OmniState(s0)] + [OmniState(cp.Variable(ns, name=f\"s{k+1}\")) for k in range(nc_short)],\n",
    "            statesbar_list=[OmniState(s0)] + [OmniState(cp.Parameter(ns)) for _ in range(nc_short)],\n",
    "            inputs_list=[OmniInput(cp.Variable(ni, name=f\"i{k}\")) for k in range(nc_short)],\n",
    "            inputsbar_list=[OmniInput(cp.Parameter(ni)) for _ in range(nc_short)],\n",
    "        )\n",
    "        robot = OmniRobot(dt=dt, mpc_data=mpc_data)\n",
    "\n",
    "        qcqp_problem_short_hor = create_qcqp(nc=nc_short)\n",
    "\n",
    "        cvxpylayer_short_hor = CvxpyLayer(\n",
    "            qcqp_problem_short_hor,\n",
    "            parameters=[weights, s0],\n",
    "            variables=[mpc_data.statei[i] for i in range(1, nc_short + 1)] + [mpc_data.inputi[i] for i in range(nc_short)],\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            w_th.copy_(torch.tensor([1.0, 1.0]))\n",
    "\n",
    "        optim = torch.optim.Adam([w_th], lr=1e-2)\n",
    "\n",
    "        n_epochs = 200\n",
    "        history  = []\n",
    "        start_time = time.time()\n",
    "        for epoch in range(n_epochs):\n",
    "            optim.zero_grad()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                s0_th.zero_()\n",
    "            \n",
    "            states, inputs = rollout(cvxpylayer_short_hor, s0_th, w_th, n_steps=n_steps_rollout)\n",
    "\n",
    "            loss = task_loss(states, inputs)\n",
    "            loss.backward()\n",
    "            \n",
    "            optim.step()\n",
    "            with torch.no_grad():\n",
    "                w_th.clamp_(min=1e-6)\n",
    "\n",
    "            history.append({\n",
    "                'loss': loss.item(),\n",
    "                'w': copy.deepcopy(w_th.detach().cpu().numpy()),\n",
    "                'dw': copy.deepcopy(w_th.grad.detach().cpu().numpy()),\n",
    "            })\n",
    "            # print(f\"Epoch {epoch:2d} | loss = {loss.item():.4f} | w = {w_th.detach().cpu().numpy()}\")\n",
    "            \n",
    "        \n",
    "        ratio = w_th.detach().cpu().numpy()[0] / w_th.detach().cpu().numpy()[1]\n",
    "        results.append({\n",
    "            'nc_short': nc_short,\n",
    "            'n_steps_rollout': n_steps_rollout,\n",
    "            'ratio': ratio,\n",
    "            'time': time.time() - start_time\n",
    "        })\n",
    "        \n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(\"data/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3568c741",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/results.csv\")\n",
    "\n",
    "fig, ax = plt.subplots(2, 1)\n",
    "\n",
    "# One line per nc_short\n",
    "for nc_short, group in df.groupby('nc_short'):\n",
    "    ax[0].plot(\n",
    "        group['n_steps_rollout'],\n",
    "        group['ratio'],\n",
    "        marker='o',\n",
    "        label=f'nc_short = {nc_short}'\n",
    "    )\n",
    "    ax[0].set_xlabel(\"n_steps_rollout\")\n",
    "    ax[0].set_ylabel(\"Ratio\")\n",
    "    ax[0].set_title(\"Effect of n_steps_rollout and nc_short on w1 / w2 ratio\")\n",
    "    \n",
    "    ax[1].plot(\n",
    "        group['n_steps_rollout'],\n",
    "        group['time'],\n",
    "        marker='o',\n",
    "        label=f'nc_short = {nc_short}'\n",
    "    )\n",
    "    ax[1].set_xlabel(\"n_steps_rollout\")\n",
    "    ax[1].set_ylabel(\"Time [s]\")\n",
    "    ax[1].set_title(\"Computation Time\")\n",
    "\n",
    "for a in ax:\n",
    "    a.legend(title='nc_short', loc='upper left', bbox_to_anchor=(1.05, 1))\n",
    "    a.set_xscale('log')\n",
    "    a.set_yscale('log')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
