{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from cycler import cycler\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import torch\n",
    "\n",
    "from dimp.robots import (\n",
    "    OmniState, OmniInput, OmniRobot, RobotMPCData\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "### Create The Data for the MPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 2      # Number of states (x, y)\n",
    "ni = 2      # Number of inputs (vx, vy)\n",
    "\n",
    "nc = 2      # Number of control intervals\n",
    "\n",
    "s0 = cp.Parameter(ns, name=\"s0\")\n",
    "\n",
    "mpc_data = RobotMPCData(\n",
    "    nc=nc,\n",
    "    states_list=[OmniState(s0)] + [OmniState(cp.Variable(ns, name=f\"s{k+1}\")) for k in range(nc)],\n",
    "    statesbar_list=[OmniState(s0)] + [OmniState(cp.Parameter(ns)) for _ in range(nc)],\n",
    "    inputs_list=[OmniInput(cp.Variable(ni, name=f\"i{k}\")) for k in range(nc)],\n",
    "    inputsbar_list=[OmniInput(cp.Parameter(ni)) for _ in range(nc)],\n",
    ")\n",
    "\n",
    "dt = 0.1\n",
    "robot = OmniRobot(dt=dt, mpc_data=mpc_data)\n",
    "\n",
    "# Parameters\n",
    "p_goal = np.array([10.0, 5.0])\n",
    "v_max = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Create The MPC Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = cp.Parameter(2, name=\"weights\", nonneg=True)\n",
    "\n",
    "def create_qcqp():\n",
    "    objective = cp.Minimize(\n",
    "          0.5 * weights[0] * cp.sum([cp.pnorm(mpc_data.statei[i+1] - p_goal, p=2) for i in range(nc)])\n",
    "        + 0.5 * weights[1] * cp.sum([cp.pnorm(mpc_data.inputi[i], p=2) for i in range(nc)])\n",
    "    )\n",
    "\n",
    "    dynamics_constraints = robot.dt_dynamics_constraint()\n",
    "\n",
    "    input_constraints = [\n",
    "        cp.norm(mpc_data.inputi[0], p=2) - v_max <= 0,\n",
    "        cp.norm(mpc_data.inputi[1], p=2) - v_max <= 0,\n",
    "    ]\n",
    "\n",
    "    constraints = dynamics_constraints + input_constraints\n",
    "\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "\n",
    "    return problem\n",
    "\n",
    "qcqp_problem = create_qcqp()\n",
    "assert qcqp_problem.is_dpp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Simulate the Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(problem, mpc_data):\n",
    "    steps = 200\n",
    "\n",
    "    states = np.zeros((steps, ns))\n",
    "    inputs = np.zeros((steps, ni))\n",
    "\n",
    "    mpc_data.statei[0].value = np.array([0, 0])\n",
    "\n",
    "    for i in range(steps):\n",
    "\n",
    "        problem.solve()\n",
    "\n",
    "        mpc_data.statei[0].value = mpc_data.statei[1].value\n",
    "\n",
    "        mpc_data.update_bar()\n",
    "\n",
    "        states[i, :] = mpc_data.statei[1].value\n",
    "        inputs[i, :] = mpc_data.inputi[1].value\n",
    "\n",
    "    return states, inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Plot the Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectory(states):\n",
    "    steps = states.shape[0]\n",
    "\n",
    "    xm, xM = states[:, 0].min() - 1, states[:, 0].max() + 1\n",
    "    ym, yM = states[:, 1].min() - 1, states[:, 1].max() + 1\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter(x=states[:, 0], y=states[:, 1],\n",
    "                        mode=\"lines\", name=\"Trajectory\",\n",
    "                        line=dict(width=2, color=\"rgba(0, 0, 255, 0.5)\", dash='dot')),\n",
    "            go.Scatter(x=[states[0, 0]], y=[states[0, 1]],\n",
    "                        mode=\"markers\", name=\"Robot\",\n",
    "                        marker=dict(color=\"blue\", size=10)),\n",
    "        ])\n",
    "\n",
    "    fig.update_layout(width=600, height=450,\n",
    "        xaxis=dict(range=[xm, xM], autorange=False, zeroline=False, scaleanchor=\"y\"),\n",
    "        yaxis=dict(range=[ym, yM], autorange=False, zeroline=False),\n",
    "        title_text=\"Trajectory\", title_x=0.5,\n",
    "        updatemenus = [dict(type = \"buttons\",\n",
    "            buttons = [\n",
    "                dict(\n",
    "                    args = [None, {\"frame\": {\"duration\": 10, \"redraw\": False},\n",
    "                                    \"fromcurrent\": True, \"transition\": {\"duration\": 10}, \"mode\": \"immediate\"}],\n",
    "                    label = \"Play\",\n",
    "                    method = \"animate\",\n",
    "                )])],\n",
    "    )\n",
    "\n",
    "    fig.update(frames=[\n",
    "        go.Frame(\n",
    "            data=[go.Scatter(x=[states[k, 0]], y=[states[k, 1]])],\n",
    "            traces=[1]\n",
    "        ) for k in range(steps)])\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    fig.write_html(\"omni_robot_mpc.html\", include_plotlyjs=\"cdn\", full_html=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_and_plot_qcqp():\n",
    "    weights.value = np.array([1.0, 0.1])\n",
    "    \n",
    "    states, inputs = simulate(qcqp_problem, mpc_data)\n",
    "\n",
    "    plot_trajectory(states)\n",
    "\n",
    "simulate_and_plot_qcqp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvxpylayer = CvxpyLayer(\n",
    "    qcqp_problem,\n",
    "    parameters=[weights, s0],\n",
    "    variables=[mpc_data.statei[i] for i in range(1, nc + 1)] + [mpc_data.inputi[i] for i in range(nc)],\n",
    ")\n",
    "\n",
    "w_th = torch.tensor([1.0, 0.1], requires_grad=True)\n",
    "s0_th = torch.tensor([0.0, 0.0], requires_grad=True)\n",
    "\n",
    "optim = torch.optim.Adam([w_th], lr=1e-1)\n",
    "\n",
    "solution = cvxpylayer(w_th, s0_th)\n",
    "\n",
    "solution[0].sum().backward()\n",
    "\n",
    "print(f\"w.grad: {w_th.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout(initial_state, W, steps=200):\n",
    "    s_t = initial_state\n",
    "    all_states, all_inputs = [], []\n",
    "\n",
    "    for _ in range(steps):\n",
    "        sol = cvxpylayer(W, s_t)\n",
    "        s1, s2, u0, u1  = sol\n",
    "\n",
    "        all_states.append(s1)\n",
    "        all_inputs.append(u0)\n",
    "\n",
    "        s_t = s1\n",
    "\n",
    "    return all_states, all_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_loss(states, inputs):\n",
    "    p_goal_th = torch.tensor(p_goal, requires_grad=True)\n",
    "    \n",
    "    st_cost = torch.stack([torch.norm(s[0:2] - p_goal_th, p=2)  for s in states]).sum()\n",
    "    in_cost = torch.stack([torch.norm(u, p=2)  for u in inputs]).sum()\n",
    "    return 0.5 * 10.0 * st_cost + 0.5 * 1.0 * in_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "history  = []\n",
    "for epoch in range(n_epochs):\n",
    "    optim.zero_grad()\n",
    "\n",
    "    s0_th.data = torch.zeros_like(s0_th)\n",
    "\n",
    "    sol = cvxpylayer(w_th, s0_th)\n",
    "    states = [sol[i] for i in range(nc)]\n",
    "    inputs = [sol[nc + i] for i in range(nc)]\n",
    "\n",
    "    loss = task_loss(states, inputs)\n",
    "    loss.backward()\n",
    "\n",
    "    optim.step()\n",
    "\n",
    "    history.append({\n",
    "        'loss': loss.item(),\n",
    "        'w': copy.deepcopy(w_th.detach().cpu().numpy()),\n",
    "        'dw': copy.deepcopy(w_th.grad.detach().cpu().numpy()),\n",
    "    })\n",
    "    print(f\"Epoch {epoch:2d} | loss = {loss.item():.4f} | w = {w_th.detach().cpu().numpy()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cycler = (\n",
    "    cycler(color=['#E41A1C', '#377EB8', '#4DAF4A', '#984EA3', '#FF7F00', '#FFFF33', '#A65628', '#F781BF', '#999999']) +\n",
    "    # cycler(color=['#0072BD', '#D95319', '#EDB120', '#7E2F8E', '#77AC30', '#4DBEEE', '#A2142F']) +\n",
    "    cycler('linestyle', ['-', '--', '-', '--', '-', '--', '-', '--', '-'])\n",
    ")\n",
    "\n",
    "colors = list(default_cycler.by_key()['color'])\n",
    "\n",
    "textsize = 12\n",
    "labelsize = 12\n",
    "\n",
    "plt.rc('font', family='serif', serif='Times')\n",
    "plt.rc('text', usetex=True)\n",
    "plt.rc('xtick', labelsize=textsize)\n",
    "plt.rc('ytick', labelsize=textsize)\n",
    "plt.rc('axes', labelsize=labelsize, prop_cycle=default_cycler)\n",
    "plt.rc('legend', fontsize=textsize)\n",
    "\n",
    "plt.rc(\"axes\", grid=True, xmargin=0)\n",
    "plt.rc(\"grid\", linestyle='dotted', linewidth=0.25)\n",
    "\n",
    "plt.rcParams['figure.constrained_layout.use'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].plot([h['loss'] for h in history])\n",
    "ax[0].set_xlabel(\"Epoch\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].set_title(\"Loss Evolution\")\n",
    "\n",
    "ax11 = ax[1].twinx()\n",
    "ax[1].plot([h['w'][0] for h in history],)\n",
    "ax[1].set_title(\"Weights Evolution\")\n",
    "ax[1].set_xlabel(\"Epoch\")\n",
    "ax[1].set_ylabel(r\"$w_0$\", color=colors[0])\n",
    "ax[1].tick_params(axis='y', labelcolor=colors[0])\n",
    "\n",
    "ax11.plot([h['w'][1] for h in history], color=colors[1], linestyle='--')\n",
    "ax11.set_ylabel(r\"$w_1$\", color=colors[1])\n",
    "ax11.tick_params(axis='y', labelcolor=colors[1])\n",
    "\n",
    "fig.set_constrained_layout(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
